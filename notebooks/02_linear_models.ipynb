{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd855f4b",
   "metadata": {},
   "source": [
    "## Linear Models\n",
    "\n",
    "In this notebook, we try to model the data using various linear regression models. We begin by import the necessary modules, as well as loading the train and test data from the train_test directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21eec000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "from mtcars_practice.config import data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b734c187",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(data_dir + '/train_test/X_train.npy')\n",
    "X_test = np.load(data_dir + '/train_test/X_test.npy')\n",
    "\n",
    "y_train = np.load(data_dir + '/train_test/y_train.npy')\n",
    "y_test = np.load(data_dir + '/train_test/y_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d8fe6b",
   "metadata": {},
   "source": [
    "We will start with linear regression. Just for curiosities sake, we try both the LinearRegression class, as well as the SGDRegressor class, since the implementations are different. The SGDRegressor actually produces a higher RMSE, probably due to the SGD algorithm settling on an unoptimal solution. We will continue with the LinearRegressor class for the rest of the the modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5d358e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1220569526033626\n"
     ]
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lin_reg.predict(X_train)\n",
    "lin_reg_rmse = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "\n",
    "print(lin_reg_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf4de10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.82700346770967\n"
     ]
    }
   ],
   "source": [
    "sgd_reg = SGDRegressor()\n",
    "sgd_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_sgd = sgd_reg.predict(X_train)\n",
    "sgd_reg_rmse = np.sqrt(mean_squared_error(y_train, y_pred_sgd))\n",
    "\n",
    "print(sgd_reg_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3706827",
   "metadata": {},
   "source": [
    "While we see that the root mean squared error is about 3 mpg over the entire training set, we would like to measure the generalizability of the model. We try using cross validation to measure this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0da587d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.78111103 3.0702988  3.81408112 3.2900013 ] \n",
      "\n",
      "Mean RMSE:  3.2388730648939728\n",
      "Std RMSE:  0.37796883501639367\n"
     ]
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "scores_lin = cross_val_score(lin_reg, X_train, y_train, scoring='neg_mean_squared_error', cv=4)\n",
    "rmse_scores_lin = np.sqrt(-scores_lin)\n",
    "\n",
    "print(rmse_scores_lin, '\\n')\n",
    "print('Mean RMSE: ', rmse_scores_lin.mean())\n",
    "print('Std RMSE: ', rmse_scores_lin.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6e333d",
   "metadata": {},
   "source": [
    "It is possible the pure linear regression model is overfitting, so we can try to regularize the model. We can try Ridge, Lasso, and Elastic Net regression to add a degree of normalization to the model.\n",
    "\n",
    "The RMSE of the Ridge regression model actually ends up being slightly higher using a coefficient of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c06829cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.82016917 3.06479369 3.84565084 3.22690326] \n",
      "\n",
      "Mean RMSE:  3.2393792396047205\n",
      "Std RMSE:  0.3787935120129052\n"
     ]
    }
   ],
   "source": [
    "ridge_reg = Ridge(alpha=0.5, solver='cholesky')\n",
    "scores_ridge = cross_val_score(ridge_reg, X_train, y_train, scoring='neg_mean_squared_error', cv=4)\n",
    "rmse_scores_ridge = np.sqrt(-scores_ridge)\n",
    "\n",
    "print(rmse_scores_ridge, '\\n')\n",
    "print('Mean RMSE: ', rmse_scores_ridge.mean())\n",
    "print('Std RMSE: ', rmse_scores_ridge.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89ecbc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.99362495 3.1981228  3.90388921 3.31271714] \n",
      "\n",
      "Mean RMSE:  3.3520885245278143\n",
      "Std RMSE:  0.3384655368117302\n"
     ]
    }
   ],
   "source": [
    "lasso_reg = Lasso(alpha=0.1)\n",
    "scores_lasso = cross_val_score(lasso_reg, X_train, y_train, scoring='neg_mean_squared_error', cv=4)\n",
    "rmse_scores_lasso = np.sqrt(-scores_lasso)\n",
    "\n",
    "print(rmse_scores_lasso, '\\n')\n",
    "print('Mean RMSE: ', rmse_scores_lasso.mean())\n",
    "print('Std RMSE: ', rmse_scores_lasso.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd33cd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.32493105 3.41076207 4.08204827 3.70663456] \n",
      "\n",
      "Mean RMSE:  3.631093989511821\n",
      "Std RMSE:  0.29637309388251093\n"
     ]
    }
   ],
   "source": [
    "elnet_reg = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "scores_elnet = cross_val_score(elnet_reg, X_train, y_train, scoring='neg_mean_squared_error', cv=4)\n",
    "rmse_scores_elnet = np.sqrt(-scores_elnet)\n",
    "\n",
    "print(rmse_scores_elnet, '\\n')\n",
    "print('Mean RMSE: ', rmse_scores_elnet.mean())\n",
    "print('Std RMSE: ', rmse_scores_elnet.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ce5c3e",
   "metadata": {},
   "source": [
    "It is possible the scores above are due to unoptimal hyperparameter selection for the normalized regression models. We will attempt to find optimal values using grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "454f43e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'alpha': array([0.01 , 0.011, 0.012, 0.013, 0.014, 0.015, 0.016, 0.017, 0.018,\n",
      "       0.019])}]\n",
      "{'alpha': 0.017999999999999995}\n"
     ]
    }
   ],
   "source": [
    "param_grid = [{'alpha': np.arange(0.01, 0.02, 0.001)}]\n",
    "print(param_grid)\n",
    "\n",
    "grid_search = GridSearchCV(Lasso(), param_grid, cv=3, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "lasso_best_params = grid_search.best_params_\n",
    "print(lasso_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca701c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'alpha': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])}]\n",
      "{'alpha': 0.30000000000000004}\n"
     ]
    }
   ],
   "source": [
    "param_grid = [{'alpha': np.arange(0.1, 1, 0.1)}]\n",
    "print(param_grid)\n",
    "\n",
    "grid_search = GridSearchCV(Ridge(solver='cholesky'), param_grid, cv=3, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "ridge_best_params = grid_search.best_params_\n",
    "print(ridge_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3943fe77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'alpha': array([0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009]), 'l1_ratio': array([0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 , 0.55,\n",
      "       0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 ])}]\n",
      "{'alpha': 0.009000000000000001, 'l1_ratio': 0.9000000000000001}\n"
     ]
    }
   ],
   "source": [
    "param_grid = [{'alpha': np.arange(0.001, 0.01, 0.001), 'l1_ratio': np.arange(0.05, 0.95, 0.05)}]\n",
    "print(param_grid)\n",
    "\n",
    "grid_search = GridSearchCV(ElasticNet(), param_grid, cv=3, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "elnet_best_params = grid_search.best_params_\n",
    "print(elnet_best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c2d785",
   "metadata": {},
   "source": [
    "Now that we have found optimal hyperparameters for the regularized linear regression models, let us test the models against the test data. We will include the regular linear regression model as a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e858f247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LinearRegression()  RMSE: 2.7556148834117464\n",
      "\n",
      "Model: Ridge(alpha=0.30000000000000004, solver='cholesky')  RMSE: 2.785089953490792\n",
      "\n",
      "Model: Lasso(alpha=0.017999999999999995)  RMSE: 2.797656188727464\n",
      "\n",
      "Model: ElasticNet(alpha=0.009000000000000001, l1_ratio=0.9000000000000001)  RMSE: 2.7901020857143037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "ridge_reg = Ridge(alpha=ridge_best_params['alpha'], solver='cholesky')\n",
    "lasso_reg = Lasso(alpha=lasso_best_params['alpha'])\n",
    "elnet_reg = ElasticNet(alpha=elnet_best_params['alpha'], l1_ratio=elnet_best_params['l1_ratio'])\n",
    "\n",
    "for model in (lin_reg, ridge_reg, lasso_reg, elnet_reg):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(f'Model: {model}  RMSE: {rmse}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
